import React, { useContext, useState, useEffect, useRef } from 'react';
import assets from '../assets/assets'; // Assuming this path is correct for your project
import { formatMessageTime } from '../lib/utils'; // Assuming this path and function are correct
import { ChatContext } from '../../context/ChatContext'; // Assuming this path is correct
import { Authcontext } from '../../context/AuthContext'; // Assuming this path is correct
import toast from 'react-hot-toast'; // Ensure this import is correct and toast is properly configured

// Video Call Hook - Encapsulates all WebRTC and video call logic
const useVideoCall = (socket, authUser, selectedUser) => {
    // State variables for managing call status and streams
    const [incomingCall, setIncomingCall] = useState(null);
    const [localStream, setLocalStream] = useState(null);
    const [remoteStream, setRemoteStream] = useState(null);
    const [isInCall, setIsInCall] = useState(false);
    const [callId, setCallId] = useState(null);
    const [connectionState, setConnectionState] = useState('disconnected');
    const [isRemoteVideoPaused, setIsRemoteVideoPaused] = useState(true); // New state for remote video playback

    // Refs for RTCPeerConnection instance and video elements
    const peerRef = useRef(null);
    const localVideoRef = useRef(null);
    const remoteVideoRef = useRef(null);
    // Ref to queue ICE candidates received before remote description is set
    const iceCandidatesQueue = useRef([]);

    // ICE servers configuration for STUN (Session Traversal Utilities for NAT)
    // These servers help peers discover their public IP addresses and ports
    const iceServers = {
        iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:stun1.l.google.com:19302' },
        ]
    };

    /**
     * Creates and configures a new RTCPeerConnection.
     * Sets up event listeners for ICE candidates, track addition, and connection state changes.
     */
    const createPeerConnection = () => {
        console.log('🔄 Creating new RTCPeerConnection');
        const peer = new RTCPeerConnection(iceServers);

        // Event handler for when an ICE candidate is generated by the local peer
        peer.onicecandidate = (event) => {
            if (event.candidate && socket) {
                console.log('🧊 Sending ICE candidate:', event.candidate);
                // Emit the ICE candidate to the signaling server to be relayed to the remote peer
                socket.emit('iceCandidate', {
                    to: selectedUser._id,
                    candidate: event.candidate,
                    callId: callId
                });
            }
        };

        // Event handler for when a remote track is received
        peer.ontrack = (event) => {
            console.log('📺 Remote stream received, tracks:', event.streams[0].getTracks());
            // Set the remote stream state, which will trigger the useEffect for remoteVideoRef
            setRemoteStream(event.streams[0]);
        };

        // Event handler for changes in the overall connection state (e.g., 'connected', 'disconnected')
        peer.onconnectionstatechange = () => {
            setConnectionState(peer.connectionState);
            console.log('🔗 Connection state:', peer.connectionState);
        };

        // Event handler for changes in the ICE connection state
        peer.oniceconnectionstatechange = () => {
            console.log('🧊 ICE connection state:', peer.iceConnectionState);
            if (peer.iceConnectionState === 'failed') {
                toast.error('Connection failed. Please try again.');
            }
        };

        // Event handler for when negotiation is needed (e.g., after adding tracks)
        peer.onnegotiationneeded = () => {
            console.log('🤝 Negotiation needed');
        };

        return peer;
    };

    /**
     * Effect hook to manage the local video stream and ensure its playback.
     * This runs whenever `localStream` changes.
     */
    useEffect(() => {
        const videoElement = localVideoRef.current;
        if (videoElement && localStream) {
            console.log('Setting local video srcObject. Stream:', localStream);
            videoElement.srcObject = localStream;

            const playVideo = async () => {
                if (!videoElement) return; // Double check element existence
                console.log('Attempting to play local video. Current state:', videoElement.paused, videoElement.ended);
                try {
                    // Attempt to play the video. Browsers often require user interaction
                    // or a 'muted' attribute for autoplay.
                    await videoElement.play();
                    console.log('Local video started playing successfully.');
                } catch (e) {
                    console.error("Error playing local video:", e);
                    // Provide user feedback if autoplay is blocked
                    if (e.name === "NotAllowedError") {
                        toast.error("Local video autoplay blocked. Please grant camera/microphone permissions.");
                    } else if (e.name === "NotReadableError") {
                        toast.error("Local video not readable. Camera might be in use by another application.");
                    } else if (e.name === "AbortError") {
                        toast.error("Local video playback aborted.");
                    } else {
                        toast.error("Error playing local video: " + e.message);
                    }
                }
            };

            playVideo(); // Try playing immediately
            videoElement.onloadedmetadata = playVideo; // Try playing once metadata is loaded

            // Add listeners to track actual playback state
            const handlePlay = () => console.log('Local video is playing.');
            const handlePause = () => console.log('Local video is paused.');
            videoElement.addEventListener('play', handlePlay);
            videoElement.addEventListener('pause', handlePause);

            console.log('Local stream video tracks:', localStream.getVideoTracks());
            console.log('Local stream audio tracks:', localStream.getAudioTracks());

            // Cleanup function: remove the event listener when component unmounts or stream changes
            return () => {
                if (videoElement) {
                    videoElement.onloadedmetadata = null; // Clean up event listener
                    videoElement.removeEventListener('play', handlePlay);
                    videoElement.removeEventListener('pause', handlePause);
                }
            };
        } else if (videoElement) {
            videoElement.srcObject = null;
            console.log('Local video srcObject cleared.');
        }
    }, [localStream]);

    /**
     * Effect hook to manage the remote video stream and ensure its playback.
     * This runs whenever `remoteStream` changes.
     */
    useEffect(() => {
        const videoElement = remoteVideoRef.current;
        if (videoElement && remoteStream) {
            console.log('Setting remote video srcObject. Stream:', remoteStream);
            videoElement.srcObject = remoteStream;

            const playVideo = async () => {
                if (!videoElement) return; // Double check element existence
                console.log('Attempting to play remote video. Current state:', videoElement.paused, videoElement.ended);
                try {
                    await videoElement.play();
                    console.log('Remote video started playing successfully.');
                    setIsRemoteVideoPaused(false); // Update state when playing
                } catch (e) {
                    console.error("Error playing remote video:", e);
                    setIsRemoteVideoPaused(true); // Set state to paused if autoplay blocked
                    if (e.name === "NotAllowedError") {
                        toast.error("Remote video autoplay blocked. Please click the 'Play Video' button.");
                    } else if (e.name === "NotReadableError") {
                        toast.error("Remote video not readable.");
                    } else if (e.name === "AbortError") {
                        toast.error("Remote video playback aborted.");
                    } else {
                        toast.error("Error playing remote video: " + e.message);
                    }
                }
            };

            playVideo(); // Try playing immediately
            videoElement.onloadedmetadata = playVideo; // Try playing once metadata is loaded

            // Add listeners to track actual playback state
            const handlePlay = () => setIsRemoteVideoPaused(false);
            const handlePause = () => setIsRemoteVideoPaused(true);
            videoElement.addEventListener('play', handlePlay);
            videoElement.addEventListener('pause', handlePause);

            console.log('Remote stream video tracks:', remoteStream.getVideoTracks());
            console.log('Remote stream audio tracks:', remoteStream.getAudioTracks());

            // Cleanup function: remove the event listener
            return () => {
                if (videoElement) {
                    videoElement.onloadedmetadata = null; // Clean up event listener
                    videoElement.removeEventListener('play', handlePlay);
                    videoElement.removeEventListener('pause', handlePause);
                }
            };
        } else if (videoElement) {
            videoElement.srcObject = null;
            console.log('Remote video srcObject cleared.');
            setIsRemoteVideoPaused(true); // Reset state if stream is cleared
        }
    }, [remoteStream]);


    /**
     * Initiates a video call to the selected user.
     * Gets local media, creates an RTCPeerConnection, creates an offer, and sends it.
     */
    const startCall = async () => {
        try {
            console.log('📞 Starting call to:', selectedUser.fullName);

            // Request access to user's camera and microphone
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true,
                audio: true
            });
            console.log('✅ Got local media stream:', stream);
            setLocalStream(stream); // Update local stream state

            const peer = createPeerConnection(); // Create a new peer connection
            peerRef.current = peer; // Store the peer connection in a ref

            // Add local media tracks to the peer connection
            stream.getTracks().forEach((track) => {
                console.log('Adding local track to peer:', track);
                peer.addTrack(track, stream);
            });

            // Create an SDP offer
            const offer = await peer.createOffer();
            // Set the local description with the created offer
            await peer.setLocalDescription(offer);
            console.log('📝 Created and set local offer:', offer);

            // Generate a unique call ID
            const newCallId = `${authUser._id}-${selectedUser._id}`;
            setCallId(newCallId);
            setIsInCall(true); // Set call status

            // Emit 'callUser' event to the signaling server
            socket.emit('callUser', {
                from: authUser._id,
                to: selectedUser._id,
                offer: offer,
                callId: newCallId
            });

            toast.success('Calling...');
        } catch (err) {
            console.error('❌ Error starting call:', err);
            toast.error('Could not start call: ' + err.message + '. Please ensure camera/microphone permissions.');
            cleanupCall(); // Clean up resources on error
        }
    };

    /**
     * Accepts an incoming video call.
     * Gets local media, creates an RTCPeerConnection, sets remote offer, creates an answer, and sends it.
     */
    const acceptCall = async () => {
        try {
            console.log('✅ Accepting call from:', selectedUser.fullName);

            // Request access to user's camera and microphone
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true,
                audio: true
            });
            console.log('✅ Got local media stream for accepting call:', stream);
            setLocalStream(stream);

            const peer = createPeerConnection(); // Create a new peer connection
            peerRef.current = peer; // Store the peer connection in a ref

            // Add local media tracks to the peer connection
            stream.getTracks().forEach((track) => {
                console.log('Adding local track to peer for accepting call:', track);
                peer.addTrack(track, stream);
            });

            // Set the remote description with the received offer
            console.log('Setting remote description with offer:', incomingCall.offer);
            await peer.setRemoteDescription(new RTCSessionDescription(incomingCall.offer));

            // Process any ICE candidates that arrived before the remote description was set
            console.log('Processing queued ICE candidates:', iceCandidatesQueue.current.length);
            while (iceCandidatesQueue.current.length > 0) {
                const candidate = iceCandidatesQueue.current.shift();
                try {
                    // Ensure peerRef.current is not null before adding candidate
                    if (peerRef.current) {
                        await peerRef.current.addIceCandidate(candidate);
                        console.log('Added queued ICE candidate:', candidate);
                    }
                } catch (e) {
                    console.error('Error adding queued ICE candidate:', e);
                }
            }

            // Create an SDP answer
            const answer = await peer.createAnswer();
            // Set the local description with the created answer
            await peer.setLocalDescription(answer);
            console.log('📝 Created and set local answer:', answer);

            setCallId(incomingCall.callId);
            setIsInCall(true); // Set call status

            // Emit 'answerCall' event to the signaling server
            socket.emit('answerCall', {
                to: incomingCall.from,
                answer: answer,
                callId: incomingCall.callId
            });

            setIncomingCall(null); // Clear incoming call state
            toast.success('Call accepted');
        } catch (err) {
            console.error('❌ Error accepting call:', err);
            toast.error('Could not accept call: ' + err.message + '. Please ensure camera/microphone permissions.');
            cleanupCall(); // Clean up resources on error
        }
    };

    /**
     * Declines an incoming call.
     * Emits a 'declineCall' event to the signaling server.
     */
    const declineCall = () => {
        console.log('❌ Declining call');
        socket.emit('declineCall', {
            to: incomingCall.from,
            callId: incomingCall.callId
        });
        setIncomingCall(null);
        toast.info('Call declined');
    };

    /**
     * Ends an active call.
     * Emits an 'endCall' event to the signaling server and cleans up local resources.
     */
    const endCall = () => {
        console.log('📴 Ending call');
        // Determine the correct recipient to send the 'endCall' signal to
        // This handles cases where the call was initiated by this user (selectedUser)
        // or received by this user (incomingCall.from)
        const recipientId = selectedUser?._id || incomingCall?.from;

        if (recipientId) {
            socket.emit('endCall', {
                to: recipientId,
                callId: callId // Use the current callId state
            });
        } else {
            console.warn('No recipient ID found for ending call.');
        }

        cleanupCall(); // Clean up all WebRTC resources
        setIsInCall(false); // Update call status
        toast.success('Call ended'); // Using toast.success for consistency
    };

    /**
     * Cleans up all WebRTC related resources (peer connection, media streams).
     */
    const cleanupCall = () => {
        console.log('🧹 Cleaning up call resources');

        // Close the RTCPeerConnection if it exists
        if (peerRef.current) {
            peerRef.current.close();
            peerRef.current = null;
            console.log('Peer connection closed.');
        }

        // Stop all tracks in the local stream and clear the state
        if (localStream) {
            localStream.getTracks().forEach(track => {
                track.stop();
                console.log('Stopped local track:', track.kind);
            });
            setLocalStream(null);
        }

        // Stop all tracks in the remote stream and clear the state
        if (remoteStream) {
            remoteStream.getTracks().forEach(track => {
                track.stop();
                console.log('Stopped remote track:', track.kind);
            });
            setRemoteStream(null);
        }

        setCallId(null);
        setConnectionState('disconnected');
        iceCandidatesQueue.current = []; // Clear any pending ICE candidates
        setIsRemoteVideoPaused(true); // Reset remote video state on cleanup
        console.log('Call resources cleaned up.');
    };

    /**
     * Effect hook to register and unregister socket event listeners for video calls.
     * This runs once on component mount and cleans up on unmount.
     */
    useEffect(() => {
        if (!socket) return; // Do nothing if socket is not available
        console.log('Registering socket event listeners...');

        // Listener for incoming call offers
        const handleIncomingCall = ({ from, offer, callId }) => {
            console.log('📞 Incoming call from:', from, 'Offer:', offer);
            setIncomingCall({ from, offer, callId }); // Set incoming call state
        };

        // Listener for when the remote peer accepts the call
        const handleCallAccepted = async ({ answer, callId }) => {
            console.log('✅ Call accepted by remote peer. Answer:', answer);
            if (peerRef.current) {
                console.log('Setting remote description with answer:', answer);
                // Set the remote description with the received answer
                await peerRef.current.setRemoteDescription(new RTCSessionDescription(answer));

                // Process any queued ICE candidates that might have arrived
                // between offer creation and answer acceptance
                console.log('Processing queued ICE candidates after answer:', iceCandidatesQueue.current.length);
                while (iceCandidatesQueue.current.length > 0) {
                    const candidate = iceCandidatesQueue.current.shift();
                    try {
                        // Ensure peerRef.current is not null before adding candidate
                        if (peerRef.current) {
                            await peerRef.current.addIceCandidate(candidate);
                            console.log('Added queued ICE candidate after answer:', candidate);
                        }
                    } catch (e) {
                        console.error('Error adding queued ICE candidate after answer:', e);
                    }
                }
            }
            toast.success('Call connected');
        };

        // Listener for when the remote peer declines the call
        const handleCallDeclined = () => {
            console.log('❌ Call declined by remote peer');
            toast.error('Call was declined');
            cleanupCall(); // Clean up resources
            setIsInCall(false);
        };

        // Listener for when the remote peer ends the call
        const handleCallEnded = ({ reason }) => {
            console.log('📴 Call ended:', reason || 'By user');
            cleanupCall(); // Clean up resources
            setIsInCall(false);
            setIncomingCall(null); // Clear incoming call state
            toast.success(reason || 'Call ended'); // Using toast.success for consistency
        };

        // Listener for incoming ICE candidates from the remote peer
        const handleIceCandidate = async ({ candidate, from, callId }) => {
            console.log('🧊 Received ICE candidate from:', from, 'Candidate:', candidate);

            const iceCandidate = new RTCIceCandidate(candidate);
            // Check if the remote description has already been set
            if (peerRef.current && peerRef.current.remoteDescription?.type) {
                try {
                    await peerRef.current.addIceCandidate(iceCandidate);
                    console.log('Added received ICE candidate to peer connection.');
                } catch (e) {
                    console.error('Error adding received ICE candidate:', e);
                }
            } else {
                // If remote description is not yet set, queue the candidate
                console.log('Queueing ICE candidate as remote description not set yet.');
                iceCandidatesQueue.current.push(iceCandidate);
            }
        };

        // Listener for general call errors from the signaling server
        const handleCallError = ({ message }) => {
            console.error('❌ Call error:', message);
            toast.error(message);
            cleanupCall();
            setIsInCall(false);
        };

        // Register all event listeners
        socket.on('incomingCall', handleIncomingCall);
        socket.on('callAccepted', handleCallAccepted);
        socket.on('callDeclined', handleCallDeclined);
        socket.on('callEnded', handleCallEnded);
        socket.on('iceCandidate', handleIceCandidate);
        socket.on('callError', handleCallError);

        // Cleanup function: unregister event listeners when the component unmounts or dependencies change
        return () => {
            console.log('Unregistering socket event listeners...');
            socket.off('incomingCall', handleIncomingCall);
            socket.off('callAccepted', handleCallAccepted);
            socket.off('callDeclined', handleCallDeclined);
            socket.off('callEnded', handleCallEnded);
            socket.off('iceCandidate', handleIceCandidate);
            socket.off('callError', handleCallError);
        };
    }, [socket, selectedUser, callId]); // Dependencies for this effect

    // Cleanup call resources when the component unmounts
    useEffect(() => {
        return () => {
            console.log('Component unmounting, cleaning up call...');
            cleanupCall();
        };
    }, []); // Empty dependency array means this runs once on mount and once on unmount

    // Return values and functions from the hook
    return {
        incomingCall,
        localStream,
        remoteStream,
        isInCall,
        connectionState,
        localVideoRef,
        remoteVideoRef,
        startCall,
        acceptCall,
        declineCall,
        endCall,
        isRemoteVideoPaused, // Expose this state
        playRemoteVideo: async () => { // Function to manually play remote video
            if (remoteVideoRef.current) {
                try {
                    await remoteVideoRef.current.play();
                    setIsRemoteVideoPaused(false);
                    console.log('Manually played remote video.');
                } catch (e) {
                    console.error('Error manually playing remote video:', e);
                    toast.error('Could not play remote video. Autoplay blocked or error: ' + e.message);
                }
            }
        }
    };
};

// Main ChatContainer component
const ChatContainer = () => {
    // Destructure values from ChatContext and Authcontext
    const { messagesMap, selectedUser, setSelectedUser, sendMessage, getMessages } = useContext(ChatContext);
    const { authUser, onlineUsers, socket } = useContext(Authcontext);

    // Ref for auto-scrolling to the end of messages
    const scrollEnd = useRef();
    // State for the message input field
    const [input, setInput] = useState('');

    // Use the custom video call hook to manage video call state and functions
    const {
        incomingCall,
        localStream,
        remoteStream,
        isInCall,
        connectionState,
        localVideoRef,
        remoteVideoRef,
        startCall,
        acceptCall,
        declineCall,
        endCall,
        isRemoteVideoPaused, // Get the state
        playRemoteVideo // Get the function to play remote video
    } = useVideoCall(socket, authUser, selectedUser);

    /**
     * Handles sending a text message.
     */
    const handleSendMessage = async (e) => {
        e.preventDefault(); // Prevent default form submission
        if (input.trim() === '') return; // Don't send empty messages
        await sendMessage({ text: input.trim() }); // Call sendMessage from context
        setInput(''); // Clear input field
    };

    /**
     * Handles sending an image message.
     */
    const handleSendImage = async (e) => {
        const file = e.target.files[0];
        if (!file || !file.type.startsWith('image/')) {
            toast.error('Please select an image file');
            return;
        }
        const reader = new FileReader();
        reader.onloadend = async () => {
            await sendMessage({ image: reader.result }); // Send image as base64
            e.target.value = ''; // Clear file input
        };
        reader.readAsDataURL(file); // Read file as Data URL
    };

    /**
     * Effect hook to fetch messages when a new user is selected.
     */
    useEffect(() => {
        if (selectedUser) {
            getMessages(selectedUser._id);
        }
    }, [selectedUser, getMessages]); // Re-run when selectedUser or getMessages changes

    /**
     * Effect hook to scroll to the end of the chat messages.
     */
    useEffect(() => {
        if (scrollEnd.current && messagesMap[selectedUser?._id]) {
            scrollEnd.current.scrollIntoView({ behavior: 'smooth' });
        }
    }, [messagesMap, selectedUser]); // Re-run when messages or selected user changes

    // Render a placeholder if no user is selected
    if (!selectedUser) {
        return (
            <div className="flex flex-col items-center justify-center gap-6 text-gray-500 max-md:hidden relative overflow-hidden">
                {/* Animated Background */}
                <div className="absolute inset-0 bg-gradient-to-br from-purple-900/20 via-blue-900/20 to-indigo-900/20">
                    <div className="absolute top-20 left-20 w-72 h-72 bg-purple-500/10 rounded-full blur-3xl animate-pulse"></div>
                    <div className="absolute bottom-20 right-20 w-96 h-96 bg-blue-500/10 rounded-full blur-3xl animate-pulse delay-1000"></div>
                </div>

                {/* Glass Effect Overlay */}
                <div className="absolute inset-0 backdrop-blur-xl bg-white/5 border-r border-white/10"></div>

                {/* Content */}
                <div className="relative z-10 flex flex-col items-center gap-6">
                    <div className="relative group">
                        <img
                            src={assets.logo_icon}
                            alt=""
                            className="max-w-20 transition-transform duration-300 group-hover:scale-110 drop-shadow-2xl"
                        />
                        <div className="absolute inset-0 bg-gradient-to-br from-purple-400/20 to-blue-400/20 rounded-full blur-xl opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div>
                    </div>
                    <div className="text-center">
                        <p className="text-2xl font-bold text-white mb-2 bg-gradient-to-r from-purple-200 to-blue-200 bg-clip-text transparent">
                            Chat anytime, anywhere
                        </p>
                        <p className="text-gray-300 text-sm opacity-80">
                            Select a conversation to start messaging
                        </p>
                    </div>
                </div>
            </div>
        );
    }

    // Main chat container UI
    return (
        <div className="h-full overflow-hidden relative">
            {/* Animated Background */}
            <div className="absolute inset-0 bg-gradient-to-br from-indigo-900/30 via-purple-900/20 to-pink-900/30">
                <div className="absolute top-0 left-1/4 w-64 h-64 bg-purple-500/10 rounded-full blur-3xl animate-pulse"></div>
                <div className="absolute bottom-0 right-1/4 w-80 h-80 bg-blue-500/10 rounded-full blur-3xl animate-pulse delay-1000"></div>
            </div>

            {/* Glass Effect Overlay */}
            <div className="absolute inset-0 backdrop-blur-xl bg-white/5 border-r border-white/10"></div>

            {/* Content */}
            <div className="relative z-10 h-full flex flex-col">
                {/* Header */}
                <div className="flex items-center gap-3 py-2 px-4 border-b h-14 border-white/10 bg-white/5 backdrop-blur-sm">
                    <div className="relative">
                        <img
                            src={selectedUser.profilePic || assets.avatar_icon}
                            alt=""
                            className="w-10 h-10 rounded-full border-2 border-white/20 shadow-lg transition-transform duration-300 hover:scale-105"
                        />
                        {onlineUsers.includes(selectedUser._id) && (
                            <span className="absolute -bottom-1 -right-1 w-3.5 h-3.5 rounded-full bg-green-500 border-2 border-white shadow-lg animate-pulse"></span>
                        )}
                    </div>

                    <div className="flex-1">
                        <p className="text-base font-semibold text-white">
                            {selectedUser.fullName}
                        </p>
                        <p className="text-xs text-gray-300">
                            {onlineUsers.includes(selectedUser._id) ? 'Online' : 'Offline'}
                            {connectionState !== 'disconnected' && (
                                <span className="ml-2 text-green-400">• {connectionState}</span>
                            )}
                        </p>
                    </div>

                    <div className="flex items-center gap-2">
                        {/* Video call button */}
                        <button
                            onClick={startCall}
                            disabled={!onlineUsers.includes(selectedUser._id) || isInCall}
                            className="bg-gradient-to-r from-purple-500 to-blue-500 hover:from-purple-600 hover:to-blue-600 disabled:opacity-50 disabled:cursor-not-allowed text-white px-3 py-1.5 rounded-lg text-sm shadow-md hover:shadow-lg transition-all duration-300 flex items-center gap-1"
                        >
                            <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                            </svg>
                            {isInCall ? 'In Call' : 'Call'}
                        </button>

                        <img
                            src={assets.arrow_icon}
                            alt=""
                            className="md:hidden w-7 h-7 cursor-pointer hover:bg-white/10 rounded-md p-1 transition-colors duration-200"
                            onClick={() => setSelectedUser(null)}
                        />
                    </div>
                </div>

                {/* Chat Area */}
                <div className="flex-1 overflow-y-auto px-2 py-1 space-y-4">
                    {messagesMap[selectedUser._id]?.map((msg, index) => (
                        <div
                            key={index}
                            className={`flex items-end gap-2 ${msg.senderId === authUser._id ? 'justify-end' : 'justify-start'}`}
                        >
                            {msg.senderId !== authUser._id && (
                                <div className="flex flex-col items-center">
                                    <img
                                        src={selectedUser?.profilePic || assets.avatar_icon}
                                        alt=""
                                        className="w-8 h-8 rounded-full border border-white/20 shadow-sm"
                                    />
                                </div>
                            )}

                            <div className="max-w-xs lg:max-w-md">
                                {msg.image ? (
                                    <div className="relative group">
                                        <img
                                            src={msg.image}
                                            alt=""
                                            className="rounded-xl shadow-lg border border-white/20 transition-transform duration-300 group-hover:scale-[1.02]"
                                        />
                                        <div className="absolute inset-0 bg-gradient-to-t from-black/20 to-transparent rounded-xl opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div>
                                    </div>
                                ) : (
                                    <div className={`p-4 rounded-2xl backdrop-blur-sm shadow-lg border transition-all duration-300 hover:shadow-xl ${
                                        msg.senderId === authUser._id
                                            ? 'bg-gradient-to-r from-purple-500/80 to-blue-500/80 text-white border-white/20 rounded-br-md'
                                            : 'bg-white/10 text-white border-white/20 rounded-bl-md'
                                    }`}>
                                        <p className="text-sm leading-relaxed break-words">{msg.text}</p>
                                    </div>
                                )}

                                <div className={`flex items-center gap-2 mt-0.5 ${
                                    msg.senderId === authUser._id ? 'justify-end' : 'justify-start'
                                }`}>
                                    {/* formatMessageTime is used here */}
                                    <p className="text-xs text-gray-400">{formatMessageTime(msg.createdAt)}</p>
                                </div>
                            </div>

                            {msg.senderId === authUser._id && (
                                <div className="flex flex-col items-center">
                                    <img
                                        src={authUser?.profilePic || assets.avatar_icon}
                                        alt=""
                                        className="w-8 h-8 rounded-full border border-white/20 shadow-sm"
                                    />
                                </div>
                            )}
                        </div>
                    ))}
                    <div ref={scrollEnd}></div>
                </div>

                {/* Input Area */}
                <div className="p-1 border-t border-white/10 bg-white/5 backdrop-blur-sm h-14">
                    <div className="flex items-center gap-2">
                        <div className="flex-1 relative">
                            <div className="bg-white/10 backdrop-blur-sm rounded-2xl border border-white/20 shadow-md hover:shadow-lg transition-all duration-300 focus-within:border-purple-400/50 focus-within:shadow-purple-500/20">
                                <div className="flex items-center px-3 py-2">
                                    <input
                                        onChange={(e) => setInput(e.target.value)}
                                        value={input}
                                        onKeyDown={(e) => (e.key === 'Enter' ? handleSendMessage(e) : null)}
                                        type="text"
                                        placeholder="Type your message..."
                                        className="flex-1 bg-transparent text-white placeholder-gray-400 outline-none text-sm"
                                    />

                                    <input
                                        onChange={handleSendImage}
                                        type="file"
                                        id="image"
                                        accept="image/png,image/jpeg"
                                        hidden
                                    />
                                    <label htmlFor="image" className="cursor-pointer">
                                        <img
                                            src={assets.gallery_icon}
                                            alt=""
                                            className="w-5 h-5 hover:scale-110 transition-transform duration-200 opacity-70 hover:opacity-100"
                                        />
                                    </label>
                                </div>
                            </div>
                        </div>

                        <button
                            onClick={handleSendMessage}
                            className="bg-gradient-to-r from-purple-500 to-blue-500 hover:from-purple-600 hover:to-blue-600 p-2.5 rounded-full shadow-md hover:shadow-lg transition-all duration-300 transform hover:scale-105 group"
                        >
                            <img
                                src={assets.send_button}
                                alt=""
                                className="w-5 h-5 group-hover:scale-110 transition-transform duration-200"
                            />
                        </button>
                    </div>
                </div>
            </div>

            {/* Enhanced Incoming Call Modal */}
            {incomingCall && (
                <div className="fixed inset-0 z-50 flex items-center justify-center animate-fade-in">
                    {/* Backdrop */}
                    <div className="absolute inset-0 bg-black/70 backdrop-blur-sm"></div>

                    {/* Modal */}
                    <div className="relative z-10 bg-white/10 backdrop-blur-xl rounded-3xl p-8 w-96 text-center shadow-2xl border border-white/20">
                        {/* Animated Ring */}
                        <div className="relative mx-auto w-24 h-24 mb-6">
                            <div className="absolute inset-0 rounded-full bg-gradient-to-r from-purple-500 to-blue-500 animate-pulse"></div>
                            <div className="absolute inset-1 rounded-full bg-white/10 backdrop-blur-sm"></div>
                            <img
                                src={selectedUser?.profilePic || assets.avatar_icon}
                                alt="caller"
                                className="absolute inset-2 w-20 h-20 object-cover rounded-full"
                            />
                        </div>

                        {/* Call Info */}
                        <div className="mb-8">
                            <p className="text-2xl font-bold text-white mb-2">
                                Incoming Video Call
                            </p>
                            <p className="text-gray-300 text-lg">
                                {selectedUser?.fullName || 'Unknown Caller'}
                            </p>
                        </div>

                        {/* Action Buttons */}
                        <div className="flex justify-center gap-6">
                            <button
                                onClick={acceptCall}
                                className="bg-gradient-to-r from-green-500 to-green-600 hover:from-green-600 hover:to-green-700 text-white px-8 py-4 rounded-2xl shadow-lg hover:shadow-xl transition-all duration-300 transform hover:scale-105 flex items-center gap-2"
                            >
                                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M3 5a2 2 0 012-2h3.28a1 1 0 01.948.684l1.498 4.493a1 1 0 01-.502 1.21l-2.257 1.13a11.042 11.042 0 005.516 5.516l1.13-2.257a1 1 0 011.21-.502l4.493 1.498a1 1 0 01.684.949V19a2 2 0 01-2 2h-1C9.716 21 3 14.284 3 6V5z" />
                                </svg>
                                Accept
                            </button>

                            <button
                                onClick={declineCall}
                                className="bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white px-8 py-4 rounded-2xl shadow-lg hover:shadow-xl transition-all duration-300 transform hover:scale-105 flex items-center gap-2"
                            >
                                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M16 8l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2M3 3l18 18" />
                                </svg>
                                Decline
                            </button>
                        </div>
                    </div>
                </div>
            )}

            {/* Enhanced Video Call Interface */}
            {isInCall && (
                <div className="fixed inset-0 bg-black z-50 flex items-center justify-center">
                    <div className="relative w-full max-w-6xl h-[90vh] bg-gray-900 rounded-2xl overflow-hidden shadow-2xl border border-gray-700">
                        {/* Remote Video */}
                        <video
                            ref={remoteVideoRef}
                            autoPlay
                            playsInline
                            className="w-full h-full object-cover"
                        />
                        {/* Play button overlay for remote video if paused */}
                        {isRemoteVideoPaused && remoteStream && (
                            <div className="absolute inset-0 flex items-center justify-center bg-black/60">
                                <button
                                    onClick={playRemoteVideo}
                                    className="bg-blue-500 hover:bg-blue-600 text-white font-bold py-3 px-6 rounded-full text-lg shadow-lg transition-all duration-300 transform hover:scale-110"
                                >
                                    ▶️ Play Video
                                </button>
                            </div>
                        )}

                        {/* Connection Status */}
                        {connectionState !== 'connected' && (
                            <div className="absolute top-4 left-4 bg-black/50 text-white px-3 py-1 rounded-lg text-sm">
                                {connectionState === 'connecting' && '🔄 Connecting...'}
                                {connectionState === 'failed' && '❌ Connection Failed'}
                                {connectionState === 'disconnected' && '📡 Reconnecting...'}
                            </div>
                        )}

                        {/* Local Video (Picture-in-Picture) */}
                        <div className="absolute bottom-6 right-6 w-48 h-36 rounded-xl overflow-hidden shadow-2xl border-2 border-white/20 bg-gray-800">
                            <video
                                ref={localVideoRef}
                                autoPlay
                                muted
                                playsInline
                                className="w-full h-full object-cover"
                            />
                            {/* Optional: Add a message if local video is not playing */}
                            {localStream && localVideoRef.current && localVideoRef.current.paused && (
                                <div className="absolute inset-0 flex items-center justify-center bg-black/50 text-white text-xs p-2 text-center">
                                    Local video paused.
                                </div>
                            )}
                        </div>

                        {/* Call Controls */}
                        <div className="absolute bottom-6 left-1/2 -translate-x-1/2 flex gap-4">
                            <button
                                onClick={endCall}
                                className="bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white px-8 py-4 rounded-full shadow-lg hover:shadow-xl transition-all duration-300 transform hover:scale-105 flex items-center gap-2"
                            >
                                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M16 8l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2M3 3l18 18" />
                                </svg>
                                End Call
                            </button>
                        </div>

                        {/* No Remote Stream Message */}
                        {!remoteStream && (
                            <div className="absolute inset-0 flex items-center justify-center bg-gray-800/50">
                                <div className="text-center text-white">
                                    <div className="animate-spin rounded-full h-16 w-16 border-b-2 border-white mx-auto mb-4"></div>
                                    <p className="text-lg">Waiting for {selectedUser?.fullName} to join...</p>
                                </div>
                            </div>
                        )}
                    </div>
                </div>
            )}
        </div>
    );
};

export default ChatContainer;